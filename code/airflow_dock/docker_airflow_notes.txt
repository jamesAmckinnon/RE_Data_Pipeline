# Starting from scratch
docker-compose down -v --remove-orphans
docker system prune -a --volumes -f
docker build . -f Dockerfile --no-cache --pull --tag airflow-cre-app
docker-compose up airflow-init
docker-compose up -d

# Building the image 
docker build -t airflow-re-app -f Dockerfile .


# Building the image after changing a requirement and then start it
docker build . --no-cache --pull --tag airflow-cre-app
    # or
    docker build . --no-cache -t airflow-cre-app
# then
docker-compose up -d

# Add Supabase connection
airflow connections add 'supabase_db_TP_IPv4' --conn-type 'postgres' --conn-login 'postgres.vdrsnwmgmdurrxsfxqpz' --conn-password '$Lw-NXz.gc6rqfp' --conn-host 'aws-0-ca-central-1.pooler.supabase.com' --conn-port '6543' --conn-schema 'postgres' 

# Entering a container
docker compose exec airflow-webserver bash

# Free space from build cache
docker system prune -a --volumes


##### Getting dags on gcp ##########

# Navigate to the airflow directory
cd /opt/airflow

# Clone your repository (replace with your actual repo URL)
git clone https://github.com/your-username/your-dags-repo.git temp-repo

# Copy your DAGs to the dags directory
cp -r temp-repo/dags/* ./dags/

# Set proper permissions
chmod -R 755 ./dags/
chown -R $USER:$USER ./dags/

# Clean up
rm -rf temp-repo

####################################
